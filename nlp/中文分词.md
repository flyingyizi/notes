
[汉字象形字典](http://vividict.com)

[NLP汉语自然语言处理原理与实践 3 词汇与分词技术](https://blog.csdn.net/qfire/article/details/78799024)

[中科院中文分词系统ICTCLAS之NShortPath代码的详细分析](https://blog.csdn.net/dancefire/article/details/1567881)

[天书般的ICTCLAS分词系统代码（一）](https://www.cnblogs.com/zhenyulu/articles/653254.html)

学习代码来源：[sego](https://github.com/huichen/sego)

[NLP-progress](https://github.com/sebastianruder/NLP-progress)

[Python下探究随机数的产生原理和算法](https://www.cnblogs.com/lzxwalex/p/6880748.html)

隐含马尔可夫模型（Hidden Markov Model）
1、简介

　　隐含马尔可夫模型并不是俄罗斯数学家马尔可夫发明的，而是美国数学家鲍姆提出的，隐含马尔可夫模型的训练方法（鲍姆-韦尔奇算法）也是以他名字命名的。隐含马尔可夫模型一直被认为是解决大多数自然语言处理问题最为快速、有效的方法。

2、马尔可夫假设

　　随机过程中各个状态St的概率分布，只与它的前一个状态St-1有关，即$P(S_t|S_1,S_2,S_3,…,S_{t-1}) = P(S_t|S_{t-1})$。比如，对于天气预报，硬性假定今天的气温只与昨天有关而和前天无关。当然这种假设未必适合所有的应用，但是至少对以前很多不好解决的问题给出了近似解。


自然语言处理到底是什么？标准定义（定义有很多，这个相对来说权威很多）1999年出版的《计算机进展》（Advanced  inComputers）第47卷上，美国计算机科学家马纳瑞斯（BillManaris）在《从人-机交互的角度看自然语言处理》一文中给自然语言处理提出的如下定义：“自然语言处理可以定义为研究在人与人交际中以及在人与计算机交际中的语言问题的一门学科。自然语言处理要研制表示语言能力（linguistic  competence）和语言应用（linguisticperformance）的模型，建立计算框架来实现这样的语言模型，提出相应的方法来不断地完善这样的语言模型，根据这样的语言模型设计各种实用系统，并探讨这些实用系统的评测技术。”这个定义的英文如下：“NLP could be defined as the discipline that studies the linguistic aspectsof human-human and human-machine communication, develops models oflinguistic competence and performance, employs computational frameworks toimplement process incorporating such models, identifies methodologies foriterative refinement of such processes/models, and investigates techniques forevaluating the result systems.”根据上面这个定义，自然语言处理要研究“在人与人交际中以及在人与计算机交际中的语言问题”，既要研究语言，又要研究计算机，因此，它是一门交叉学科，它涉及语言学、计算机科学、数学、自动化技术等不同的学科

## NLP-数学基础

在基于统计方法的自然语言处理研究中，有关统计学和信息论等方面的知识是不可缺少的基础

- 最大似然估计(最大可能性估计)

    如果进行n次实验（n趋向于无穷大），我们把某个时间发生的相对频率叫默认为时间的发生概率，用这样的方法来计算概率，这个方法就叫做最大似然估计

    最大似然估计是利用已知的样本的结果，在使用某个模型的基础上，反推最有可能导致这样结果的模型参数值。

- 条件概率

    如果$A$和$B$样本空间$\Omega$上的两个事件，$P(B)>0$,那么，在给定$B$时$A$的条件概率contiditonal probalility $P(A|B)$ 为$P(A|B) = \frac{P(A \bigcap B)}{P(B)}$

- 贝叶斯法则
    $$P(Y|X) = \frac{P(X|Y) P(Y)}{P(X)}$$

    https://www.jianshu.com/p/01f69b7f61a7


- 先验概率 ( Prior probability)

    先验概率是在缺乏某个事实的情况下描述一个变量; 而后验概率是在考虑了一个事实之后的条件概率.  先验概率通常是经验丰富的专家的纯主观的估计. 比如在法国大选中女候选罗雅尔的支持率 p,  在进行民意调查之前, 可以先验概率来表达这个不确定性.

- 验概率 ( posterior probability)

    Def: Probability of outcomes of an experiment after it has been performed and a certain event has occured.  

    后验概率可以根据通过Bayes定理, 用先验概率和似然函数计算出来.  下面的公式就是用先验概率密度乘上似然函数,接着进行归一化, 得到不定量X在Y=y的条件下的密度,即后验概率密度:

    $$f_{X\mid Y=y}(x)={f_X(x) L_{X\mid Y=y}(x) \over {\int_{-\infty}^\infty f_X(x) L_{X\mid Y=y}(x)\,dx}}$$

    其中$f_X(x)$ 为X的先验密度, $L_{X | Y} = y^{(x)} = f_{Y | X} = x^{(y)}$ 为似然函数..