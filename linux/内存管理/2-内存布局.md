
以下内容涉及linux source版本为“4.14.21”，如果不特殊说明，都是以arm32 arch相关的内容。


# 内存布局

在“linux\Documentation\arm\memory.txt”描述了arm32 visual memory layout：

本节内容尝试对每个segment 从代码角度对它们进行解读。该解读基于ARM32已经开启MMU,以及HEIGHMEM（即CONFIG_HIGHMEM已定义）

```
// linux\Documentation\arm\memory.txt
Start		End		Use
--------------------------------------------------------------------------
ffff8000	ffffffff	copy_user_page / clear_user_page use.
				For SA11xx and Xscale, this is used to
				setup a minicache mapping.

ffff4000	ffffffff	cache aliasing on ARMv6 and later CPUs.

ffff1000	ffff7fff	Reserved.
				Platforms must not use this address range.

ffff0000	ffff0fff	CPU vector page.        
				The CPU vectors are mapped here if the
				CPU supports vector relocation (control
				register V bit.)

fffe0000	fffeffff	XScale cache flush area.  This is used
				in proc-xscale.S to flush the whole data
				cache. (XScale does not have TCM.)

fffe8000	fffeffff	DTCM mapping area for platforms with
				DTCM mounted inside the CPU.

fffe0000	fffe7fff	ITCM mapping area for platforms with
				ITCM mounted inside the CPU.

ffc00000	ffefffff	Fixmap mapping region.  Addresses provided
				by fix_to_virt() will be located here.

fee00000	feffffff	Mapping of PCI I/O space. This is a static
				mapping within the vmalloc space.

VMALLOC_START	VMALLOC_END-1	vmalloc() / ioremap() space.
				Memory returned by vmalloc/ioremap will
				be dynamically placed in this region.
				Machine specific static mappings are also
				located here through iotable_init().
				VMALLOC_START is based upon the value
				of the high_memory variable, and VMALLOC_END
				is equal to 0xff800000.

PAGE_OFFSET	high_memory-1	Kernel direct-mapped RAM region.
				This maps the platforms RAM, and typically
				maps all platform RAM in a 1:1 relationship.

PKMAP_BASE	PAGE_OFFSET-1	Permanent kernel mappings
				One way of mapping HIGHMEM pages into kernel
				space.

MODULES_VADDR	MODULES_END-1	Kernel module space
				Kernel modules inserted via insmod are
				placed here using dynamic mappings.

00001000	TASK_SIZE-1	User space mappings
				Per-thread mappings are placed here via
				the mmap() system call.

00000000	00000fff	CPU vector page / null pointer trap
				CPUs which do not support vector remapping
				place their vector page here.  NULL pointer
				dereferences by both the kernel and user
				space are also caught via this mapping.
```

下面的图是内核内存布局的概图，每个部分建立页表映射的时机见后面各小节的描述。

```
arm32:



            PKMAP_BASE/                                             PCI_IO_VIRT_BASE+    FIXADDR_START    VECTORS_BASE
           MODULES_END          high_memory                           IO_SPACE_LIMIT         │                   │
 MODULES_VADDR  │      PAGE_OFFSET   │    VMALLOC_START   PCI_IO_VIRT_BASE     │ VMALLOC_END │      FIXADDR_END  │  4GB
      │         │          │         │       │                           │     │       │     │           │       │   │
      ▼         ▼          │         ▼       ▼                           ▼     ▼       ▼     │           ▼       ▼   │
      ┌─────────┬──────────┼─────────┬───────┬───────┬───\\────┬───────┬─┬─────┬───────┐ ────┼───────────┬───────┬───┤
      │         │PMD_SIZE  │ physical│  8MB  │       │   4KB   │       │ │     │       │     │           │       │   │
      │         │ ◄─────►  │ memory  │◄─────►│ malloc│◄───────►│vmalloc│ │     │       │     │           │       │   │
      │         │          │ mapping │       │area   │         │area   │ │     │       │     │           │       │   │
      └─────────┴──────────┴─────────┴───────┴───────┴───\\────┴───────┴─┴─────┴───────┘ ────┴───────────┴───────┴───┘
                                                                         ▲             ▲     ▲           ▲       ▲
                                                                         │             │     │ 0xfff00000│       │
                                                                   0xfee00000 0xff800000 0xffc00000         0xffff0000

x86:
                                                      PKMAP_BASE
          high_memory                                     │           
  PAGE_OFFSET  │    VMALLOC_START           VMALLOC_END   │     FIXADDR_START   4GB
     │         │       │                         │        │          │           │
     ▼         ▼       ▼                         ▼        │          │           │
     ┌─────────┬───────┬───────┬─ \\   ──┬───────┬────────┼──────────┼───────────┤
     │ physical│  8MB  │       │   4KB   │       │  8KB   │persistent│ fix-mapped│
     │ memory  │◄─────►│vmalloc│◄───────►│vmalloc│◄──────►│kernel    │   linear  │
     │ mapping │       │area   │         │area   │        │mappings  │ address   │
     └─────────┴───────┴───────┴─  \\  ──┴───────┴────────┴──────────┴───────────┘
```



## [00001000,TASK_SIZE-1] User space mappings


以linux视角，对这个VA空间可以从大的方面分为：用户空间与内核空间. “[00001000,TASK_SIZE-1]” 就是所谓用户空间。高于TASK_SIZE部分的VA由所有进程使用，称它们为“kernel segment”。

通常有人简单称用户空间与内核空间的的分割点是"`PAGE_OFFSET`"，严格来说这是不准确的，在后面将会看到“[TASK_SIZE,PAGE_OFFSET]”会被内核使用到。

根据代码中定义：

```c++
//C:\home\rpi-kernels\linux\include\linux\sizes.h
#define SZ_16M				0x01000000

//C:\home\rpi-kernels\linux\arch\arm\include\asm\memory.h
/*
 * TASK_SIZE - the maximum size of a user space task.
 * TASK_UNMAPPED_BASE - the lower boundary of the mmap VM area
 */
#define TASK_SIZE		(UL(CONFIG_PAGE_OFFSET) - UL(SZ_16M))
```

实际中用户空间与内核空间之间还设置了一段空间作为GAP，这个GAP大小是"UL(SZ_16M)".

在用户空间的每个task（task_struct），通过"mmap() system call"映射内存并使用内存。

## [MODULES_VADDR,MODULES_END-1] Kernel module space

这段空间由模块使用，在加载模块时进行动态页表映射。动态映射方面的处理与对HEIGHMEM的处理一样。

位置定义：根据下面的代码片段，我们可以知道这段VA空间几乎与“user space”相邻：
```c++
//linux\arch\arm\include\asm\memory.h
/*
 * The module space lives between the addresses given by TASK_SIZE
 * and PAGE_OFFSET - it must be within 32MB of the kernel text.
 */
#ifndef CONFIG_THUMB2_KERNEL
#define MODULES_VADDR		(PAGE_OFFSET - SZ_16M)
#else
/* smaller range for Thumb-2 symbols relocation (2^24)*/
#define MODULES_VADDR		(PAGE_OFFSET - SZ_8M)
#endif

#if TASK_SIZE > MODULES_VADDR
#error Top of user space clashes with start of module space
#endif

/*
 * The highmem pkmap virtual space shares the end of the module area.
 */
#define MODULES_END		(PAGE_OFFSET - PMD_SIZE)
```


按照约定，这段VA空间是用于“Kernel modules inserted via insmod are placed here using dynamic mappings.”. 这也是最早的约定，但在新内核中情况有所变化，变化的不是这段VA空间的用途，而是模块空间被扩展了：Linux新的内核引入module PLT(Procedure Link Table)机制，让模块加载增加了使用vmalloc空间（也属于内核空间）的方法，解决模块空间不够用的问题。该配置见“linux\arch\arm\Kconfig”中的“config ARM_MODULE_PLTS”：
```
config ARM_MODULE_PLTS
	bool "Use PLTs to allow module memory to spill over into vmalloc area"
	depends on MODULES
	...

	  Say y if you are getting out of memory errors while loading modules
```

注意，这段空间的页表不是在内核入口中进行页表映射的，所以你不会在内核入口（head.s , start_kernel ...）找到对它的映射。 下面的我们就来描述下找到它相关页表映射的建立过程。

"`insmod`"的内核态实现是由系统调用sys_init_module实现。空间分配是由“`module_alloc`”实现，参见在“linux\kernel\module.c”文件中体现如下调用关系："`系统调用sys_init_module-->init_module-->load_module-->layout_and_allocate-->move_module-->module_alloc`"。

```c++
//linux\arch\arm\kernel\module.c
void *module_alloc(unsigned long size)
{
	gfp_t gfp_mask = GFP_KERNEL;
	void *p;

	/* Silence the initial allocation */
	if (IS_ENABLED(CONFIG_ARM_MODULE_PLTS))
		gfp_mask |= __GFP_NOWARN;
    /**
	 * __vmalloc_node_range 函数作用：该函数是vmalloc的主要实现，用来从(start, end)中申请一段大小为size的虚拟地址空间，并
	 * 给这块虚拟地址空间申请物理内存(基本是不连续的)，并通过"map_vm_area"写入页表。
	 * 对 __vmalloc_node_range 函数的详细解读可以参考：[vmalloc详解](https://blog.csdn.net/weixin_30655219/article/details/95782764)
	*/
    /**
	 * 先尝试在传统module空间[MODULES_VADDR, MODULES_END] 申请
	*/
	p = __vmalloc_node_range(size, 1, MODULES_VADDR, MODULES_END,
				gfp_mask, PAGE_KERNEL_EXEC, 0, NUMA_NO_NODE,
				__builtin_return_address(0));
	/**
	 * 如果申请失败，并且开启了MODULE_PLTS，就继续
	 * 如果申请成功，或申请失败 则返回
	*/
	if (!IS_ENABLED(CONFIG_ARM_MODULE_PLTS) || p)
		return p;
	/**
	 * 尝试在[VMALLOC_START, VMALLOC_END]申请
	 */	
	return __vmalloc_node_range(size, 1,  VMALLOC_START, VMALLOC_END,
				GFP_KERNEL, PAGE_KERNEL_EXEC, 0, NUMA_NO_NODE,
				__builtin_return_address(0));
}
```

## [PKMAP_BASE,PAGE_OFFSET-1] Permanent kernel mappings
				One way of mapping HIGHMEM pages into kernel
				space.
位置定义：
```c++
//linux\arch\arm\include\asm\highmem.h
#define PKMAP_BASE		(PAGE_OFFSET - PMD_SIZE)
```
联系前面的“`#define MODULES_END		(PAGE_OFFSET - PMD_SIZE)`”,显然这两个VA空间紧邻。

这段VA空间在内核启动阶段"`start_kernel-->setup_arch-->paging_init-->kmap_init`"，通过early_pte_alloc进行相应pte分配填充挂接到pgd，即完成对应映射表项建立
```c++
//linux\arch\arm\mm\mmu.c
static void __init kmap_init(void)
{
#ifdef CONFIG_HIGHMEM
	pkmap_page_table = early_pte_alloc(pmd_off_k(PKMAP_BASE),
		PKMAP_BASE, _PAGE_KERNEL_TABLE);
#endif

	early_pte_alloc(pmd_off_k(FIXADDR_START), FIXADDR_START,
			_PAGE_KERNEL_TABLE);
}

```

[高端内存映射之kmap持久内核映射](https://cloud.tencent.com/developer/article/1381079)

## [PAGE_OFFSET,high_memory-1] Kernel direct-mapped RAM region.
				This maps the platforms RAM, and typically
				maps all platform RAM in a 1:1 relationship.

通过内核启动阶段的"`start_kernel-->setup_arch-->paging_init-->map_lowmem`"对lowmem建立映射，其中map_lowmem创建映射的范围是"`[KERNEL_START, __init_end]`"，该范围值是有链接脚本“vmlinux.lds.S”中规定的。 map_lowmem对这个范围创建映射时额外附加了1M边界对齐修正。

位置定义：
```c++
//linux\arch\arm\include\asm\memory.h
#define KERNEL_START		_stext
#define KERNEL_END		_end
```

```c++
//linux\arch\arm\kernel\vmlinux.lds.S
SECTIONS
{
	... /* lots */
	. = PAGE_OFFSET + TEXT_OFFSET;
	.head.text : {
		_text = .;
		HEAD_TEXT
	}
	... /* lots */
	.text : {			/* Real text segment		*/
		_stext = .;		/* Text and read-only data	*/
    	... /* lots */
	}
	... /* lots */
	_etext = .;			/* End of text section */
	... /* lots */
	__init_begin = .;
	... /* lots */
	__init_end = .;
	__data_loc = .;

	.data : AT(__data_loc) {
		_data = .;		/* address in memory */
		_sdata = .;
    	... /* lots */
		_edata = .;
	}
	... /* lots */
	BSS_SECTION(0, 0, 0)
	_end = .;

	STABS_DEBUG
}
```

## [VMALLOC_START,VMALLOC_END-1] vmalloc() / ioremap() space.
				Memory returned by vmalloc/ioremap will
				be dynamically placed in this region.
				Machine specific static mappings are also
				located here through iotable_init().
				VMALLOC_START is based upon the value
				of the high_memory variable, and VMALLOC_END
				is equal to 0xff800000.

这段内核VA空间被用于：分配在虚拟内存中连续但在物理内存中不一定连续的内存。接口函数是vmalloc.

内核为了管理VMALLOC区域, 内核必须跟踪哪些子区域被使用、哪些是空闲的. 为此定义了一个数据结构vm_struct。


位置定义：

   ```c++
   //linux\arch\arm\include\asm\pgtable.h
   /*
   * Just any arbitrary offset to the start of the vmalloc VM    rea: the
   * current 8MB value just means that there will be a 8MB    hole" after the
   * physical memory until the kernel virtual memory starts.     hat means that
   * any out-of-bounds memory accesses will hopefully be caught.
   * The vmalloc() routines leaves a hole of 4kB between each    malloced
   * area for the same reason. ;)
   */
   #define VMALLOC_OFFSET		(8*1024*1024)
   #define VMALLOC_START		(((unsigned long)high_memory +    MALLOC_OFFSET) & ~(VMALLOC_OFFSET-1))
   #define VMALLOC_END		0xff800000UL
   ```

	注：在"`setup_arch-->adjust_lowmem_bounds`"中会对high_memory进行赋值，具体见下面的“计算high_memory”中详细说明。
	注： 感觉采用类似“`# define VMALLOC_END   (PKMAP_BASE - 2 * PAGE_SIZE)`”应该更合适，为什么实际是硬编码


### 计算high_memory

很多系统都基于前提：认为high_memory定义在direct map memory的上边界，并在ZONE_NORMAL的末尾。

high_memory 的计算是位于setup_arch中两次adjust_lowmem_bounds得到的。在第二次（前面已经reserve kernel部分）才得到真正的结果。

   ```c++
   void __init setup_arch(char **cmdline_p)
   {
   	/*
   	 * Make sure the calculation for lowmem/highmem is set appropriately
   	 * before reserving/allocating any mmeory
   	 */
   	/**
   	 * 第一次调用adjust_lowmem_bounds，仅仅是为了memblock 首次
     * 设置 current_limit ，因为在任何memblock_add/reserve 执行前，
	 * 这个current_limit都需要根据  场景合适的设置
   	*/
   	adjust_lowmem_bounds();  //第一次计算得到的
   	arm_memblock_init(mdesc); // reserve 
   	/* Memory may have been removed so recalculate the bounds. */
   	adjust_lowmem_bounds();  //第二次计算后，high_memory, arm_lowmem_limit 才是正确的
   
   	early_ioremap_reset();
   
   	paging_init(mdesc);
       ...
   }	
   ```


下面的"`adjust_lowmem_bounds`"函数是采用 从 "`VMALLOC_END`" 往低处不断尝试的方式，在memblock.memory 里面查找
```c++
//linux\mm\memory.c
/*
 * A number of key systems in x86 including ioremap() rely on the assumption
 * that high_memory defines the upper bound on direct map memory, then end
 * of ZONE_NORMAL.  Under CONFIG_DISCONTIG this means that max_low_pfn and
 * highstart_pfn must be the same; there must be no gap between ZONE_NORMAL
 * and ZONE_HIGHMEM.
 */
void *high_memory;
EXPORT_SYMBOL(high_memory);


//linux\arch\arm\mm\mmu.c
void __init adjust_lowmem_bounds(void)
{
	phys_addr_t memblock_limit = 0;
	u64 vmalloc_limit;
	struct memblock_region *reg;
	phys_addr_t lowmem_limit = 0;

	/*
	 * vmalloc_min是采取reserve等行为更新后新的vmalloc_end。
	 * 通过它得到是以0为base address的新vmalloc end：vmalloc_limit。
	 * 这个转换目的是为了后续能与reg->base进行比较
	 */
	vmalloc_limit = (u64)(uintptr_t)vmalloc_min - PAGE_OFFSET + PHYS_OFFSET;

    /**
	 * 赋值 lowmem_limit ， lowmem_limit的意义是low-memory-end 
	*/
	for_each_memblock(memory, reg) {
		phys_addr_t block_start = reg->base;
		phys_addr_t block_end = reg->base + reg->size;
        /**
		 * 显然如果该memory block位于vmalloc end之后是不需要考虑的
		*/
		if (reg->base < vmalloc_limit) {
			if (block_end > lowmem_limit)
				/*
				 * Compare as u64 to ensure vmalloc_limit does
				 * not get truncated. block_end should always
				 * fit in phys_addr_t so there should be no
				 * issue with assignment.
				 */
				lowmem_limit = min_t(u64,
							 vmalloc_limit,
							 block_end);

			/*
			 * Find the first non-pmd-aligned page, and point
			 * memblock_limit at it. This relies on rounding the
			 * limit down to be pmd-aligned, which happens at the
			 * end of this function.
			 *
			 * With this algorithm, the start or end of almost any
			 * bank can be non-pmd-aligned. The only exception is
			 * that the start of the bank 0 must be section-
			 * aligned, since otherwise memory would need to be
			 * allocated when mapping the start of bank 0, which
			 * occurs before any free memory is mapped.
			 */
			if (!memblock_limit) {
				if (!IS_ALIGNED(block_start, PMD_SIZE))
					memblock_limit = block_start;
				else if (!IS_ALIGNED(block_end, PMD_SIZE))
					memblock_limit = lowmem_limit;
			}

		}
	}
    // 赋值global var
	arm_lowmem_limit = lowmem_limit;
    // 赋值global var
	high_memory = __va(arm_lowmem_limit - 1) + 1;

	if (!memblock_limit)
		memblock_limit = arm_lowmem_limit;

	/*
	 * Round the memblock limit down to a pmd size.  This
	 * helps to ensure that we will allocate memory from the
	 * last full pmd, which should be mapped.
	 */
	memblock_limit = round_down(memblock_limit, PMD_SIZE);

	if (!IS_ENABLED(CONFIG_HIGHMEM) || cache_is_vipt_aliasing()) {
		if (memblock_end_of_DRAM() > arm_lowmem_limit) {
			phys_addr_t end = memblock_end_of_DRAM();

			pr_notice("Ignoring RAM at %pa-%pa\n",
				  &memblock_limit, &end);
			pr_notice("Consider using a HIGHMEM enabled kernel.\n");

			memblock_remove(memblock_limit, end - memblock_limit);
		}
	}

	memblock_set_current_limit(memblock_limit);
}
```



## [fee00000,feffffff] Mapping of PCI I/O space. 
                This is a static
				mapping within the vmalloc space.

位置定义：
```c++
//linux\arch\arm\include\asm\io.h
/* PCI fixed i/o mapping */
#define PCI_IO_VIRT_BASE	0xfee00000
...
#define IO_SPACE_LIMIT	... //不同机器差别挺大
...
```

它是属于vmalloc space，因此页表映射的建立一般来说应该需要使用时才建立。下面介绍了建立时机：

对于io，存在：常用的ioremap或者of_iomap都是动态映射，静态映射的接口是iotable_init

如果是静态映射，一般是在"`start_kernel-->setup_arch-->paging_init-->devicemaps_init-->[mdesc->map_io()]`"中通过调用iotable_init 达到目的。在iotable_init中回去完成页表映射等。 对应的这需要对 machine desc 赋值 map_io 函数。

如果是动态映射，现在驱动程序中更推荐使用基于设备树的of_iomap, 它是对传统ioremap的包装。页表映射的创建是通过: "`ioremap-->__arm_ioremap_caller-->__arm_ioremap_pfn_caller-->ioremap_page_range`"


## [ffc00000,ffefffff] Fixmap mapping region.  
                Addresses provided
				by fix_to_virt() will be located here.

位置定义：
```c++
//C:\home\rpi-kernels\linux\arch\arm\include\asm\fixmap.h
#define FIXADDR_START		0xffc00000UL
#define FIXADDR_END		0xfff00000UL
#define FIXADDR_TOP		(FIXADDR_END - PAGE_SIZE)
```

这段VA空间在内核启动阶段"`start_kernel-->setup_arch-->paging_init-->kmap_init`"，通过early_pte_alloc进行相应pte分配填充挂接到pgd，即完成对应映射表项建立
```c++
//linux\arch\arm\mm\mmu.c
static void __init kmap_init(void)
{
#ifdef CONFIG_HIGHMEM
	pkmap_page_table = early_pte_alloc(pmd_off_k(PKMAP_BASE),
		PKMAP_BASE, _PAGE_KERNEL_TABLE);
#endif

	early_pte_alloc(pmd_off_k(FIXADDR_START), FIXADDR_START,
			_PAGE_KERNEL_TABLE);
}

```



## [fffe0000,fffe7fff] ITCM mapping area 
                for platforms with
				ITCM mounted inside the CPU.

位置定义：

```c++
//linux\arch\arm\include\asm\memory.h
/*
 * We fix the TCM memories max 32 KiB ITCM resp DTCM at these
 * locations
 */
#ifdef CONFIG_HAVE_TCM
#define ITCM_OFFSET	UL(0xfffe0000)
#define DTCM_OFFSET	UL(0xfffe8000)
#endif
```

这段VA空间在内核启动阶段"`start_kernel-->setup_arch-->paging_init-->tcm_init-->iotable_init`"进行页表创建。


## [fffe8000,fffeffff]	DTCM mapping area 
                for platforms with
				DTCM mounted inside the CPU.

位置定义：

```c++
//linux\arch\arm\include\asm\memory.h
/*
 * We fix the TCM memories max 32 KiB ITCM resp DTCM at these
 * locations
 */
#ifdef CONFIG_HAVE_TCM
#define ITCM_OFFSET	UL(0xfffe0000)
#define DTCM_OFFSET	UL(0xfffe8000)
#endif
```

这段VA空间在内核启动阶段"`start_kernel-->setup_arch-->paging_init-->tcm_init-->iotable_init`"进行页表创建。


## [ffff0000,ffff0fff]	CPU vector page.                   
				The CPU vectors are mapped here if the
				CPU supports vector relocation (control
				register V bit.)

位置定义： 虽然在“linux\arch\arm\Kconfig”有“config VECTORS_BASE”选项，但从代码看应该是没有起作用。

[0xffff0000, 0xffff0000 + 2* PAGE_SIZE]

在"`start_kernel-->setup_arch-->paging_init-->devicemaps_init`"中通过调用create_mapping中回去完成页表映射等。

```c++
static void __init devicemaps_init(const struct machine_desc *mdesc)
{
	struct map_desc map;
	unsigned long addr;
	void *vectors;

	/*
	 * Allocate the vector page early.
	 */
	vectors = early_alloc(PAGE_SIZE * 2);
    /**
	 * 根据"__vectors_start, __vectors_end"内容，准备vectors内容。
	*/
	early_trap_init(vectors);

	...

	/*
	 * Create a mapping for the machine vectors at the high-vectors
	 * location (0xffff0000).  If we aren't using high-vectors, also
	 * create a mapping at the low-vectors virtual address.
	 */
	map.pfn = __phys_to_pfn(virt_to_phys(vectors));
	map.virtual = 0xffff0000;
	map.length = PAGE_SIZE;
#ifdef CONFIG_KUSER_HELPERS
	map.type = MT_HIGH_VECTORS;
#else
	map.type = MT_LOW_VECTORS;
#endif
	create_mapping(&map);

	if (!vectors_high()) {
		map.virtual = 0;
		map.length = PAGE_SIZE * 2;
		map.type = MT_LOW_VECTORS;
		create_mapping(&map);
	}

	/* Now create a kernel read-only mapping */
	map.pfn += 1;
	map.virtual = 0xffff0000 + PAGE_SIZE;
	map.length = PAGE_SIZE;
	map.type = MT_LOW_VECTORS;
	create_mapping(&map);

	...
}

```


## [ffff4000,ffffffff] cache aliasing on ARMv6 and later CPUs.

```c++
//linux\arch\arm\mm\mm.h
/* PFN alias flushing, for VIPT caches */
#define FLUSH_ALIAS_START	0xffff4000
```

CONFIG_CPU_CACHE_VIPT

### cache组织方式
本文主要讲述如何根据虚拟地址或物理地址来寻找cache，及各种方案的优劣比较。在阅读前，需要对cache基本工作原理及MMU工作原理有一定了解，比如cache的映射方式(直接映射，组相联，全相联)，虚拟地址到物理地址的转换过程及TLB等。

- VIVT(Virtual Index Virtual Tag)

	使用虚拟地址做索引，虚拟地址做Tag。早期的ARM处理器一般采用这种方式，在查找cache line过程中不借助物理地址，这种方式会导致cache别名(cache alias)问题。比如当两个虚拟地址对应相同物理地址，并且没有映射到同一cache行，那么就会产生问题。另外，当发生进程切换时，由于页表可能发生变化，所以要对cache进行invalidate等操作，效率较低。

- VIPT(Virtual Index Physical Tag)

	使用虚拟地址做索引，物理地址做Tag。在利用虚拟地址索引cache同时，同时会利用TLB/MMU将虚拟地址转换为物理地址。然后将转换后的物理地址，与虚拟地址索引到的cache line中的Tag作比较，如果匹配则命中。这种方式要比VIVT实现复杂，当进程切换时，不在需要对cache进行invalidate等操作(因为匹配过程中需要借物理地址)。但是这种方法仍然存在cache别名的问题(即两个不同的虚拟地址映射到同一物理地址，且位于不同的cache line)，但是可以通过一定手段解决。

	了解MMU转换过程的话应该知道，以4KB页大小为例，对于物理地址与其对应的虚拟地址，bit[0] -- bit[11]低12位是相同的，如果两个虚拟地址映射到了同一个物理地址，那么这两个虚拟地址的低12位一定是相同的。在利用Virtual Index查找cache line时(这里假定cache使用4路组相联的方式)，如果能保证Virtual Index的位数包含在bit[0] -- bit[11]中，那么就能保证两个虚拟地址会查找到同一个cache line组内，由于物理地址相同，在利用Tag在组内进行匹配时，一定会找到同一个cache line，进而解决cache alias问题。针对上述描述，这里详细举例说明：假定L1 cache大小为16KB， 4路组相联， cache line为32。现有物理地址0x00000120，虚拟地址为0xe0001120及0xf0002120同时映射到该物理地址(4KB页映射，虚拟地址和物理地址低12位相同)。由于cache大小为16KB，cache line为32(bit[0] – bit[4])，由于4路组相联，所以用于Virtual Index的位数为 log (16KB / 32 / 4) = 7即 (bit[5] – bit[11])，这样针对两个虚拟地址0xe0001120及0xf0002120由于低12位相同，那么一定会映射到同一个cache组内，然后利用物理地址作为Tag在组内匹配cache line，一定会找到同一个cache line。那么问题来了，我现在的cache大小为32KB，那么用于Virtual Index的位数为 log (32KB / 32 / 4) = 7即 (bit[5] – bit[12])，这样两个个虚拟地址0xe0001120及0xf0002120的bit[12]不同，所以就会寻找到不同的cache组内，这样就会造成同一物理地址存在于两个cache line内，造成cache alias。针对这种情况，可以有两种解决方法，调整映射页大小，超过4KB，这样能保证两个虚拟地址低位相同的位数涵盖用于Virtual Index的位数。另一种方式通过软件解决，Page Colouring Restrictions。详细方法可以查看链接网址。无论是通过修改页大小还是通过软件方式解决VIPT的cache alias问题，核心思想就是让不同的虚拟地址查找到同一个cache组，这样在利用物理Tag进行组内多路cache匹配时，就一定会找到同一个cache line，那么如何能保证不同的虚拟地址查找到同一个cache组呢？那就是让两个不同的虚拟地址地址低位相同的位数涵盖用于Virtual Index的位数

- PIPT(Physical Index Physical Tag)

	使用物理地址做索引，物理地址做Tag。现代的ARM Cortex-A大多采用PIPT方式，由于采用物理地址作为Index和Tag，所以不会产生cache alias问题。不过PIPT的方式在芯片的设计要比VIPT复杂得多，而且需要等待TLB/MMU将虚拟地址转换为物理地址后，才能进行cache line寻找操作。


## [ffff8000,ffffffff] copy_user_page / clear_user_page use.
				For SA11xx and Xscale, this is used to
				setup a minicache mapping.

```c++
//linux\arch\arm\mm\mm.h
/*
 * 0xffff8000 to 0xffffffff is reserved for any ARM architecture
 * specific hacks for copying pages efficiently, while 0xffff4000
 * is reserved for VIPT aliasing flushing by generic code.
 *
 * Note that we don't allow VIPT aliasing caches with SMP.
 */
#define COPYPAGE_MINICACHE	0xffff8000
#define COPYPAGE_V6_FROM	0xffff8000
#define COPYPAGE_V6_TO		0xffffc000
```


